{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 设置 CSV 文件所在的文件夹路径\n",
    "csv_folder = r\"D:\\Microsoft VS Code\\uwants\"\n",
    "\n",
    "# 初始化一个空的 DataFrame 用于合并\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# 遍历文件夹中的所有 CSV 文件\n",
    "for file in os.listdir(csv_folder):\n",
    "    if file.endswith('.csv'):  # 确保只处理 CSV 文件\n",
    "        file_path = os.path.join(csv_folder, file)\n",
    "        \n",
    "        # 使用 UTF-8-SIG 编码读取文件\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "            merged_df = pd.concat([merged_df, df], ignore_index=True)  # 合并到总的 DataFrame 中\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file}: {e}\")\n",
    "            continue\n",
    "\n",
    "# 数据清洗和标准化\n",
    "try:\n",
    "    # 基于 URL 去除重复值\n",
    "    if '帖子URL' in merged_df.columns:  # 确保列存在\n",
    "        merged_df = merged_df.drop_duplicates(subset='帖子URL', keep='first')  # 保留首次出现的记录\n",
    "    else:\n",
    "        print(\"URL column not found, skipping deduplication.\")\n",
    "\n",
    "    # 基于时间列去除空值\n",
    "    if '最初發表時間' in merged_df.columns:  # 确保列存在\n",
    "        merged_df = merged_df.dropna(subset=['最初發表時間'])  # 删除时间为空的行\n",
    "    else:\n",
    "        print(\"Time column not found, skipping removal of rows with null time.\")\n",
    "\n",
    "    # 字段名标准化映射\n",
    "    column_mapping = {\n",
    "        '搜索关键词': 'keyword',\n",
    "        '帖子标题': 'title',\n",
    "        '帖子内容': 'post_content',\n",
    "        '帖子URL': 'url',\n",
    "        '作者': 'username',\n",
    "        '回复内容': 'replies',\n",
    "        '最初發表時間': 'post_time'\n",
    "    }\n",
    "\n",
    "    # 替换字段名\n",
    "    merged_df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "    # 删除 \"版區\" 列（如果存在）\n",
    "    if '版區' in merged_df.columns:\n",
    "        merged_df = merged_df.drop(columns=['版區'])\n",
    "\n",
    "    # 拆分 \"回覆/查看\" 列为 \"reply_number\" 和 \"view_number\"\n",
    "    if '回覆/查看' in merged_df.columns:\n",
    "        merged_df[['reply_number', 'view_number']] = merged_df['回覆/查看'].str.split('/', expand=True)\n",
    "        merged_df['reply_number'] = pd.to_numeric(merged_df['reply_number'], errors='coerce').fillna(0).astype(int)\n",
    "        merged_df['view_number'] = pd.to_numeric(merged_df['view_number'], errors='coerce').fillna(0).astype(int)\n",
    "        merged_df = merged_df.drop(columns=['回覆/查看'])  # 删除原始列\n",
    "\n",
    "    # 新增 \"platform\" 列，固定值为 \"uwants\"\n",
    "    merged_df['platform'] = 'uwants'\n",
    "\n",
    "    # 清理 post_time 列中的无关文字\n",
    "    if 'post_time' in merged_df.columns:\n",
    "        # 移除包含 \"只看該作者分享\" 的部分\n",
    "        merged_df['post_time'] = merged_df['post_time'].str.replace(r'只看該作者分享', '', regex=True).str.strip()\n",
    "        \n",
    "        # 转换时间格式为 YYYY-MM-DD HH:MM:SS\n",
    "        merged_df['post_time'] = pd.to_datetime(merged_df['post_time'], errors='coerce').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # 保存最终标准化的文件\n",
    "    output_file = r'D:\\Microsoft VS Code\\uwants\\final_standardized_file.csv'\n",
    "    merged_df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Data cleaning and standardization completed and saved to {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during data cleaning and standardization: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里需要手动将时间那里列名替换成post_time，然后再运行以下代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 当前文件路径\n",
    "input_file = r'D:\\Microsoft VS Code\\uwants\\final_standardized_file.csv'\n",
    "output_file = r'D:\\Microsoft VS Code\\uwants\\processed_file.csv'\n",
    "\n",
    "try:\n",
    "    # 读取文件\n",
    "    df = pd.read_csv(input_file, encoding='utf-8-sig')\n",
    "\n",
    "    # 检查是否存在 \"post_time\" 列\n",
    "    if 'post_time' in df.columns:\n",
    "        # 移除 \"post_time\" 列中的无效文字 \"只看該作者分享\"\n",
    "        df['post_time'] = df['post_time'].str.replace(r'只看該作者分享', '', regex=True).str.strip()\n",
    "\n",
    "        # 删除 \"post_time\" 列中为空值的行\n",
    "        df = df.dropna(subset=['post_time'])\n",
    "\n",
    "        # 将 \"post_time\" 转换为标准时间格式\n",
    "        df['post_time'] = pd.to_datetime(df['post_time'], errors='coerce').dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # 再次删除无法解析为时间格式的行\n",
    "        df = df.dropna(subset=['post_time'])\n",
    "\n",
    "    else:\n",
    "        print(\"The column 'post_time' does not exist in the dataset.\")\n",
    "\n",
    "    # 保存处理后的文件\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Post time column successfully processed and saved to {output_file}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during processing: {e}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
